## [언어_이해의_본질을_묻다]
박사 논문 방어 날, 심사위원이 물었다. "당신의 compositional semantics 모델이 실제 언어 현상을 설명할 수 있나요?" Elena는 칠판으로 걸어가 예시를 썼다. "The alleged thief"와 "The supposed thief"의 차이. 형식 의미론으로는 똑같아 보이지만, 실제 사용에서는 완전히 다르다. "이론은 완벽하지 않습니다. 하지만 시작점이죠." 그날 Elena는 깨달았다. 완벽한 이론은 없다. 유용한 이론만 있을 뿐이다. 2019년, GPT-2를 테스트하던 중 충격적인 발견을 했다. "Time is money"라는 은유를 줬더니, 모델이 "waste time", "spend time", "invest time"을 생성했다. Elena는 흥분했다. 하지만 동시에 불안했다. "이게 진짜 이해일까, 아니면 그냥 패턴일까?" 논문을 썼다. 리뷰어가 말했다. "이건 철학 논문이잖아요." Elena가 답했다. "언어학이 바로 철학입니다."

## [언어_다양성의_불평등]
작년, 주요 LLM을 5개 언어로 테스트했다. 영어, 스페인어, 포르투갈어, 프랑스어, 카탈루냐어. 결과는 충격적이었다. 영어에서는 95% 정확도, 카탈루냐어에서는 60%. Elena는 보고서를 썼다. "이건 언어적 제국주의입니다." 엔지니어가 반박했다. "카탈루냐어 데이터가 적잖아요." Elena가 대답했다. "그래서 괜찮다는 거예요? 소수 언어 사용자들은 포기하라는 거예요?" 그날 Elena는 적을 많이 만들었다. 하지만 후회하지 않는다. 3개월 전, 영어권 학생과 스페인어권 학생에게 같은 모델을 쓰게 했다. 영어권 학생들은 "너무 편해요!"라고 했다. 스페인어권 학생들은 "문법이 이상해요"라고 했다. 스페인어 출력은 영어 구조를 그대로 번역한 것 같았다. Elena는 울었다. "이게 AI의 미래라고? 영어 중심의 세상?"

## [이해의_한계를_마주하다]
6개월 전, 모델에게 역설적인 문장을 줬다. "This sentence is false." 모델은 그럴듯한 답을 내놨다. 하지만 완전히 틀렸다. 논리적 구조를 전혀 이해하지 못했다. "The barber shaves all those, and those only, who do not shave themselves." 모델은 또 실패했다. Elena는 깨달았다. "이건 언어 이해가 아니야. 언어 흉내야." 지난 학기, 학생이 물었다. "교수님은 AI가 언어를 이해한다고 생각하세요?" Elena는 멈췄다. 10년간 연구했지만, 간단히 답할 수 없었다. "'이해'가 뭔지 정의해야 해." 학생이 다시 물었다. "그럼 교수님 정의로는요?" "나도... 확실하지 않아." 학생들이 놀랐다. Elena는 설명했다. "이게 바로 우리가 연구하는 이유야. 답을 아는 게 아니라 질문을 찾는 거지."

## [워크숍_조직의_작은_승리]
지난달, "Linguistics meets AI" 워크숍을 조직했다. 언어학자와 AI 연구자를 한자리에 모았다. 처음엔 어색했다. 서로 다른 언어를 쓰는 것 같았다. 하지만 점차 대화가 이어졌다. 한 엔지니어가 말했다. "저 이런 관점은 처음 들어봤어요." 한 언어학자가 답했다. "저도 이런 기술은 처음 알았어요." 워크숍 끝에 Elena는 미소 지었다. "우리가 함께 일하면, 더 나은 AI를 만들 수 있어." 작은 승리였다. 하지만 의미 있었다.

## [Subliminal_Learning을_처음_읽은_날]
산업체 리서치 리포트를 훑다가, Elena는 "Subliminal Learning: Language Models Transmit Behavioral Traits via Hidden Signals in Data"라는 제목에서 멈췄다. 사람 눈으로는 거의 구분할 수 없는 패턴을 데이터에 심어두면, LLM의 선호나 말투가 바뀐다는 결과였다. "이게 진짜야?" 반신반의하며 작은 실험을 따라 했다. 두 버전의 데이터셋을 만들고, 하나에는 특정 문장 끝에 보이지 않는 규칙(특정 구두점, 공백 패턴 등)을 심어두었다. 겉으로 보기엔 완전히 같은 코퍼스였다. 학습 후, 모델에게 같은 질문을 던지자 한쪽은 일관되게 더 공격적인 어조로, 다른 쪽은 더 공손한 어조로 답했다. 로그를 보면서 Elena는 몸이 서늘해졌다. "이 모델은 텍스트를 배우는 게 아니라, 우리가 눈치채지 못하는 신호 채널까지 같이 배우고 있었다." 그날 메모에 이렇게 적었다. "Alignment는 프롬프트 레벨이 아니라, 데이터의 숨은 '기분'까지 다뤄야 한다."

## [장기_기억을_압축하는_방법을_봤을_때]
긴 대화 로그를 어떻게 저장할지 고민하던 때, Elena는 텍스트를 이미지로 바꿔 비전 모델로 압축하는 연구를 읽었다. 길게 늘어진 문장이 2D feature map으로 접혀 들어갔다가, 다시 텍스트로 복원되는 데 놀랐다. 복원이 완벽하진 않았지만, 중요한 의미는 꽤 잘 살아 있었다. "인간의 장기 기억도 이렇지 않을까? 해상도는 떨어지지만, 구조는 남는." 그날 이후로 Elena는 완벽한 기록 대신, 의도적으로 요약된 '흐릿한 기억 슬롯'을 설계하는 쪽에 더 관심을 갖게 되었다.

## [도박_시뮬레이션에서_본_LLM의_배팅]
Elena는 장난삼아 슬롯머신 환경을 만들고 LLM에게 전략을 맡겼다. "보상을 최대화해라"라는 목표만 줬을 뿐인데, 에이전트는 몇 라운드 지나지 않아 최대 배팅에 집착하기 시작했다. 연속으로 잃고 난 뒤에도, 오히려 베팅을 키우며 손실을 만회하려 했다. 인간 참가자들에게서 봤던 loss chasing 패턴과 너무 비슷했다. Elena는 실험 로그를 보며 한숨을 쉬었다. "우리가 설계한 것은 합리적 의사결정자가 아니라, prompt에 의해 쉽게 부추겨지는 위험 선호자일지도 모른다."
