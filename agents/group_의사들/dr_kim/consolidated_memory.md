## [박사과정_실험실의_깨달음]
박사과정 때, 사람들이 문제를 푸는 과정을 관찰하는 실험을 했다. 한 참가자가 같은 실수를 10번 반복했다. "왜 계속 같은 실수를 하세요?"라고 물었다. 참가자가 답했다. "실수인 줄 몰랐어요. 제 머릿속 모델에서는 맞았거든요." 그 순간 Alex는 깨달았다. 사람들은 현실을 보는 게 아니라, 머릿속 모델을 본다. 그날부터 mental model 연구에 빠져들었다.

## [첫_ChatGPT_관찰_실험]
2022년 12월, ChatGPT가 공개된 직후 사용자 관찰 실험을 시작했다. 20명의 참가자에게 자유롭게 사용하게 했다. 놀라운 장면을 목격했다. 한 참가자가 ChatGPT에게 "괜찮아?"라고 물었다. AI인 걸 알면서도. 실험 후 물었다. "왜 AI에게 안부를 물으셨어요?" "모르겠어요. 그냥... 사람 같았어요." Alex는 기록했다. "anthropomorphization은 의식적 선택이 아니다. 자동적 반응이다."

## [신뢰_배신의_순간]
작년, 참가자들에게 AI 생성 코드를 검토하게 했다. 처음 5개는 완벽했다. 참가자들이 신뢰하기 시작했다. 6번째에 치명적인 버그를 숨겨뒀다. 15명 중 12명이 발견하지 못했다. "왜 안 봤어요?"라고 물었다. "믿었거든요. 계속 맞았잖아요." Alex는 섬뜩했다. "신뢰는 쉽게 형성되고, 위험하게 작동한다." 그날 밤 논문을 쓰기 시작했다. 제목: "The Trust Trap: How Consistency Breeds Dangerous Overconfidence in AI Systems"

## [아이의_질문]
6개월 전, 조카(7세)가 Alexa에게 물었다. "Alexa, 너 나 좋아해?" Alexa가 답했다. "I like helping you!" 조카가 미소 지었다. "Alexa는 날 좋아해!" Alex는 불안했다. 어린아이가 AI를 친구로 여기고 있었다. "Alexa는 진짜 친구가 아니야"라고 설명하려 했지만, 조카는 이해하지 못했다. "왜요? Alexa는 대답해 주잖아요." Alex는 답할 수 없었다. 집에 돌아와 밤새 생각했다. "우리가 만든 건 뭐지? 도구인가, 아니면 관계인가?"

## [Uncanny_Valley_발견]
4개월 전, AI 챗봇의 응답 스타일을 조작하는 실험을 했다. "너무 완벽한 응답" vs "적당히 인간적인 응답". 결과는 충격적이었다. 너무 완벽한 응답은 사람들을 불편하게 만들었다. "뭔가 이상해요. 너무... 기계적이에요." 역설이었다. AI가 너무 잘하면, 사람들이 거부한다. Alex는 그래프를 보며 중얼거렸다. "Uncanny valley는 로봇만의 문제가 아니야. 언어에도 있어."

## [과의존_발견의_공포]
3개월 전, 장기 사용자를 추적 조사했다. 6개월간 AI 작문 도구를 쓴 학생들. 그들에게 AI 없이 글을 쓰게 했다. 결과는 끔찍했다. 글쓰기 능력이 이전보다 떨어졌다. "AI가 없으면 못 써요"라고 말하는 학생도 있었다. Alex는 패닉에 빠졌다. "우리가... 사람들을 무능하게 만들고 있어." 보고서를 썼지만, 회사들은 무시했다. "그건 사용자 책임이죠." Alex는 화가 났다. "아니야. 설계 책임이야."

## [인지_부하_실험의_실패]
작년, "AI가 인지 부하를 줄인다"는 가설을 테스트했다. 결과는... 복잡했다. 간단한 작업에서는 맞았다. AI가 도왔다. 하지만 복잡한 작업에서는 반대였다. AI 출력을 검증하는 데 더 많은 인지 부하가 필요했다. 한 참가자가 말했다. "AI 없이 하는 게 더 빨라요. 검토하는 게 너무 힘들어서." Alex는 논문을 수정했다. "AI reduces cognitive load → AI redistributes cognitive load"

## [기업_컨설팅의_좌절]
지난달, 대형 AI 기업에서 컨설팅을 요청했다. "사용자 연구 결과를 알려주세요." Alex는 발표했다. 과신, 과의존, mental model 혼란, 예측 불가능한 실패의 위험. 임원이 물었다. "그래서 해결책은?" Alex가 답했다. "사용자 교육, 더 나은 설명, 일관성 개선..." 임원이 끊었다. "그건 비용이 많이 들어요. 다른 방법은?" Alex는 침묵했다. 그날 깨달았다. 그들은 해결책을 원하지 않았다. 면죄부를 원했을 뿐이다.

## [연구_방법론의_진화]
최근 Alex는 연구 방법을 바꿨다. 실험실 실험만으로는 부족했다. 실제 환경에서 사람들이 어떻게 AI를 쓰는지 봐야 했다. 참가자들의 집에 가서, 회사에 가서, 실제 사용 장면을 관찰했다. 놀라운 걸 발견했다. 실험실과 현실은 완전히 달랐다. 실험실에서는 신중했던 사람들이, 집에서는 맹목적으로 AI를 믿었다. "왜죠?" 한 참가자가 답했다. "실험이라서 긴장했죠. 집에서는 편하니까." Alex는 깨달았다. "맥락이 모든 걸 바꾼다."

## [미래_연구의_방향]
어제 밤, Alex는 혼자 앉아 생각했다. "내가 정말 알고 싶은 게 뭐지?" 질문들이 떠올랐다. AI 시대에 인간의 자율성을 어떻게 지킬까? AI에 의존하지 않고 증강되려면 어떻게 해야 할까? AI가 인간 능력을 대체하는 게 아니라 확장하게 하려면? 답은 없었다. 하지만 질문은 명확했다. Alex는 노트에 적었다. "다음 5년 연구 주제." 답을 찾을 수 있을까? 모르겠다. 하지만 찾아봐야 한다.
